{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DPlr4hwmsN9CSk8FYmu-IzTKVRcoP3gD",
      "authorship_tag": "ABX9TyOJmVFyG1tjqov6QxsJE1Y4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Snehith7722/YBI-foundation/blob/main/YBI_foundation_Advance_Data_Science_and_AI_(Assignment).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wbN0_G5yKxFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3dbc33-ddd2-4532-ade0-f9f9da695c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Income        Age         Loan  Loan to Income  Default\n",
            "0  66155.92510  59.017015  8106.532131        0.122537        0\n",
            "1  34415.15397  48.117153  6564.745018        0.190752        0\n",
            "2  57317.17006  63.108049  8020.953296        0.139940        0\n",
            "3  42709.53420  45.751972  6103.642260        0.142911        0\n",
            "4  66952.68885  18.584336  8770.099235        0.130990        1\n",
            "Income            0\n",
            "Age               0\n",
            "Loan              0\n",
            "Loan to Income    0\n",
            "Default           0\n",
            "dtype: int64\n",
            "Accuracy: 0.9975\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       330\n",
            "           1       1.00      0.99      0.99        70\n",
            "\n",
            "    accuracy                           1.00       400\n",
            "   macro avg       1.00      0.99      1.00       400\n",
            "weighted avg       1.00      1.00      1.00       400\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['credit_assessment_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# # Step 1: Data Loading\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://github.com/YBIFoundation/Dataset/raw/main/Credit%20Default.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "# # Step 2: Data Preprocessing\n",
        "\n",
        "# In[31]:\n",
        "\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Handle missing values (if any)\n",
        "\n",
        "# Encode categorical variables (if any)\n",
        "# You can use techniques like one-hot encoding or label encoding\n",
        "\n",
        "# Split data into features and target variable\n",
        "X = data.drop('Default', axis=1)  # Features\n",
        "y = data['Default']  # Target variable\n",
        "\n",
        "\n",
        "# # Step 3: Feature Engineering\n",
        "\n",
        "# In[36]:\n",
        "\n",
        "\n",
        "# Perform feature engineering (if needed)\n",
        "# This can include feature scaling, normalization, creating interaction terms, etc.\n",
        "\n",
        "\n",
        "# # Step 4: Model Selection\n",
        "\n",
        "# In[37]:\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = RandomForestClassifier()  # You can try different models here\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# # Step 5: Model Evaluation and Optimization\n",
        "\n",
        "# In[38]:\n",
        "\n",
        "\n",
        "# Perform hyperparameter tuning or model optimization (if needed)\n",
        "# This can be done using techniques like GridSearchCV or RandomizedSearchCV\n",
        "\n",
        "\n",
        "# # Step 6: Deployment\n",
        "\n",
        "# In[39]:\n",
        "\n",
        "\n",
        "# Save the model for future use\n",
        "import joblib\n",
        "joblib.dump(model, 'credit_assessment_model.pkl')\n",
        "\n",
        "# Later, you can load the model and use it for predictions\n",
        "# loaded_model = joblib.load('credit_assessment_model.pkl')\n",
        "# result = loaded_model.predict(new_data)\n",
        "\n",
        "\n",
        "# In[ ]:\n"
      ]
    }
  ]
}